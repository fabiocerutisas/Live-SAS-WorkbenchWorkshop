{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "from sasviya.ml.linear_model import LogisticRegression\n",
    "from sasviya.ml.tree import ForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting and Modelling\n",
    "In this section we start by defining key variables such as:\n",
    "- data_path = here we pass the path to the modelling_data we have previously prepared \n",
    "- columns_to_exclude = we specify which columns from the set of available ones we should exclude when fitting the models\n",
    "- target = specify the target variable\n",
    "- train_frac = portion of data for training\n",
    "- valid_frac = portion of data for validation\n",
    "- test_frac = portion of data for testing\n",
    "\n",
    "Next, we split the data into train, validation and test by stratifying on the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/cleaned_data/train_valid_test.csv'\n",
    "features = ['CreditPolicy', 'PublicRecord',  'Purpose', 'InterestRate', 'Installment','Delinquencies2Yrs', \n",
    "            'BIN_CreditLineAge', 'BIN_DebtIncRatio', 'BIN_FICOScore','BIN_Inquiries6Mnths', 'BIN_LogAnnualInc', \n",
    "            'BIN_RevBalance','BIN_RevUtilization']\n",
    "target = 'Default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_transform_credit_data = pd.read_csv(data_path)\n",
    "\n",
    "train = woe_transform_credit_data[woe_transform_credit_data['_PartInd_']==1].reset_index(drop=True)\n",
    "valid = woe_transform_credit_data[woe_transform_credit_data['_PartInd_']==2].reset_index(drop=True)\n",
    "test = woe_transform_credit_data[woe_transform_credit_data['_PartInd_']==3].reset_index(drop=True)\n",
    "\n",
    "train_defaults = train[target].sum()\n",
    "valid_defaults = valid[target].sum()\n",
    "test_defaults = test[target].sum()\n",
    "print('Train Size:', train.shape[0], f'--- {target} Frequency:', f'{round(100*train_defaults/train.shape[0],2)}%')\n",
    "print('Valid Size:', valid.shape[0], f'--- {target} Frequency:', f'{round(100*valid_defaults/valid.shape[0],2)}%')\n",
    "print('Test Size:', test.shape[0], f'--- {target} Frequency:', f'{round(100*test_defaults/test.shape[0],2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "#Fit on Train Data\n",
    "logistic_model.fit(train[features], train[target])\n",
    "train_preds_logistic = logistic_model.predict(train[features])\n",
    "valid_preds_logistic = logistic_model.predict(valid[features])\n",
    "#Fit on Train and Valid Data\n",
    "train_valid = pd.concat([train, valid])\n",
    "logistic_model.fit(train_valid[features], train_valid[target])\n",
    "test_preds_logistic = logistic_model.predict(test[features])\n",
    "#Compute Fit Metrics\n",
    "train_f1_logistic = f1_score(train[target], train_preds_logistic)\n",
    "valid_f1_logistic = f1_score(valid[target], valid_preds_logistic)\n",
    "test_f1_logistic = f1_score(test[target], test_preds_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = ForestClassifier()\n",
    "#Fit on Train Data\n",
    "forest_model.fit(train[features], train[target])\n",
    "train_preds_forest = forest_model.predict(train[features])\n",
    "valid_preds_forest = forest_model.predict(valid[features])\n",
    "#Fit on Train and Valid Data\n",
    "train_valid = pd.concat([train, valid])\n",
    "forest_model.fit(train_valid[features], train_valid[target])\n",
    "test_preds_forest = forest_model.predict(test[features])\n",
    "#Compute Fit Metrics\n",
    "train_f1_forest = f1_score(train[target], train_preds_forest)\n",
    "valid_f1_forest = f1_score(valid[target], valid_preds_forest)\n",
    "test_f1_forest = f1_score(test[target], test_preds_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = pd.DataFrame(\n",
    "    {'Logistic': [train_f1_logistic, valid_f1_logistic, test_f1_logistic], \n",
    "    'Forest': [train_f1_forest, valid_f1_forest, test_f1_forest]},\n",
    "    ['Train F1', 'Valid F1', 'Test F1'])\n",
    "100*model_comparison.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(20,5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(test[target], test_preds_logistic, normalize='true'))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axs[0])\n",
    "axs[0].set_title('Test Confusion Matrix - Logistic')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(test[target], test_preds_forest, normalize='true'))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axs[1])\n",
    "axs[1].set_title('Test Confusion Matrix - Forest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Task\n",
    "\n",
    "Develop a Gradient Boosting Model, test different hyperparameters and compare its performance against the above trained Logistic and Forest Models.\n",
    "\n",
    "![GB Classifier Overview](../img/GB_Details_Python.png)\n",
    "\n",
    "For further guidance: https://go.documentation.sas.com/doc/en/workbenchcdc/v_001/explore/n1kiea90s0276wn1xr0ig0hvkix6.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sasviya.ml.tree import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, fit it and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to compute the Train F1, Valid F1 and Test F1\n",
    "model_comparison = pd.DataFrame(\n",
    "    {'Logistic': [train_f1_logistic, valid_f1_logistic, test_f1_logistic], \n",
    "    'Forest': [train_f1_forest, valid_f1_forest, test_f1_forest],\n",
    "    'GB': [_________]},\n",
    "    ['Train F1', 'Valid F1', 'Test F1'])\n",
    "100*model_comparison.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce confusion matrices to compare performance against the Logistic Regression and the Gradient Boosting\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(20,5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(test[target], test_preds_logistic, normalize='true'))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axs[0])\n",
    "axs[0].set_title('Test Confusion Matrix - Logistic')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(test[target], test_preds_forest, normalize='true'))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axs[1])\n",
    "axs[1].set_title('Test Confusion Matrix - Forest')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(test[target], _______, normalize='true'))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axs[2])\n",
    "axs[2].set_title('Test Confusion Matrix - GB')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_path = '../data/cleaned_data/synthetic_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = pd.read_csv(synthetic_data_path)\n",
    "\n",
    "train = pd.concat([train, synthetic_data])\n",
    "train_defaults = train[target].sum()\n",
    "valid_defaults = valid[target].sum()\n",
    "test_defaults = test[target].sum()\n",
    "print('Train Size:', train.shape[0], f'--- {target} Frequency:', f'{round(100*train_defaults/train.shape[0],2)}%')\n",
    "print('Valid Size:', valid.shape[0], f'--- {target} Frequency:', f'{round(100*valid_defaults/valid.shape[0],2)}%')\n",
    "print('Test Size:', test.shape[0], f'--- {target} Frequency:', f'{round(100*test_defaults/test.shape[0],2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Task\n",
    "\n",
    "Train a GradientBoosting Classifier with the newly augmented train dataset and evaluate its performance.\n",
    "\n",
    "- Are there any deltas in the Fit Metrics?\n",
    "- Produce a table to directly compare fit metrics with and without synthetic data\n",
    "- Produce the newly achieved confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to compute the Train F1, Valid F1 and Test F1\n",
    "model_comparison = pd.DataFrame(\n",
    "    {'Logistic': [train_f1_logistic, valid_f1_logistic, test_f1_logistic], \n",
    "    'Forest': [train_f1_forest, valid_f1_forest, test_f1_forest],\n",
    "    'GB': [________],\n",
    "    'GB+Synth':[________]},\n",
    "    ['Train F1', 'Valid F1', 'Test F1'])\n",
    "100*model_comparison.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce confusion matrices to compare performance against the Logistic Regression and the Gradient Boosting\n",
    "fig, axs = plt.subplots(ncols=4, figsize=(20,5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(test[target], test_preds_logistic, normalize='true'))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axs[0])\n",
    "axs[0].set_title('Test Confusion Matrix - Logistic')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(test[target], test_preds_forest, normalize='true'))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axs[1])\n",
    "axs[1].set_title('Test Confusion Matrix - Forest')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(test[target], ______, normalize='true'))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axs[2])\n",
    "axs[2].set_title('Test Confusion Matrix - GB')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(test[target], ________, normalize='true'))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axs[3])\n",
    "axs[3].set_title('Test Confusion Matrix - GB+Synth')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Models\n",
    "We create an artifacts folder and save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'artifacts'\n",
    "if not os.path.isdir(mypath):\n",
    "   os.makedirs(mypath)\n",
    "\n",
    "logistic_model.save('artifacts/logistic_model.pkl')\n",
    "forest_model.save('artifacts/forest_model.pkl')\n",
    "#Your GB Model\n",
    "#Your GB + Synth Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
