{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering to Model Manager\n",
    "This notebook exemplifies how to register a model developed in Workbench to Model Manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests \n",
    "import os\n",
    "import sasviya \n",
    "from sasctl import Session, pzmm\n",
    "from sasctl.services import model_repository as mr\n",
    "import pickle \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://innovationlab.demo.sas.com/\"\n",
    "\n",
    "def _connect_to_instance(refresh_token, verification):\n",
    "\tauth_url = f\"{url}/SASLogon/oauth/token\"\n",
    "\t# reading long-lived refresh token from txt file\n",
    "\n",
    "\tpayload=f'grant_type=refresh_token&refresh_token={refresh_token}'\n",
    "\theaders = {\n",
    "\t'Accept': 'application/json',\n",
    "\t'Content-Type': 'application/x-www-form-urlencoded',\n",
    "\t'Authorization': 'Basic c2FzLmNsaTo=',\n",
    "\t}\n",
    "\n",
    "\tresponse = requests.request(\"POST\", auth_url, headers=headers, data=payload, verify=verification)\n",
    "\taccess_token = response.json()['access_token']\n",
    "\treturn access_token\n",
    "\n",
    "def _generate_access_token(auth_code, verification): \n",
    "\tserver = f\"{url}/SASLogon/oauth/token\"\n",
    "\n",
    "\tpayload = f'grant_type=authorization_code&code={auth_code}'\n",
    "\theaders = {\n",
    "\t\t'Accept': 'application/json',\n",
    "\t\t'Content-Type': 'application/x-www-form-urlencoded',\n",
    "\t\t'Authorization': 'Basic c2FzLmNsaTo='\n",
    "\t}\n",
    "\n",
    "\tresponse = requests.request(\"POST\", server, headers=headers, data=payload, verify=verification)\n",
    "\n",
    "\t# Parse the response text\n",
    "\tresponse_json = json.loads(response.text)\n",
    "\n",
    "\t# Get the refresh token\n",
    "\trefresh_token = response_json['refresh_token']\n",
    "\treturn refresh_token\n",
    "\n",
    "def get_connection(verify=False):\n",
    "\tif 'refresh_token.txt' not in [i.name for i in os.scandir()]:\n",
    "\t\twith open('refresh_token.txt', 'w') as file:\n",
    "\t\t\tfile.write('test')\n",
    "\tif verify:\n",
    "\t\tos.environ['CAS_CLIENT_SSL_CA_LIST'] = 'innovation_lab.pem'\n",
    "\t\tverify = 'innovation_lab.pem'\n",
    "\ttry:\n",
    "\t\twith open('refresh_token.txt', 'r') as token:\n",
    "\t\t\trefresh_token = token.read()\n",
    "\t\taccess_token = _connect_to_instance(refresh_token, verify)\n",
    "\n",
    "\texcept:\n",
    "\t\tprint(f'{url}/SASLogon/oauth/authorize?client_id=sas.cli&response_type=code')\n",
    "\t\tauth_code = input(f'Please provide your access token by going to {url}/SASLogon/oauth/authorize?client_id=sas.cli&response_type=code:')\n",
    "\t\trefresh_token = _generate_access_token(auth_code, verify)\n",
    "\t\twith open('refresh_token.txt', 'w') as file:\n",
    "\t\t\tfile.write(refresh_token)\n",
    "\t\taccess_token = _connect_to_instance(refresh_token, verify)\n",
    "\t\twith open('access_token.txt', 'w') as file:\n",
    "\t\t\tfile.write(access_token)\n",
    "\tprint('Connected!')\n",
    "\treturn access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = get_connection(verify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = Session(url, token=access_token)\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"Live_SAS_WBWorkshop_Python\"\n",
    "repository_name = \"DMRepository\"\n",
    "\n",
    "repository = mr.get_repository(repository_name)\n",
    "\n",
    "project = mr.get_project(project_name)\n",
    "\n",
    "if project == None:\n",
    "    project = mr.create_project(project_name, repository)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register sasviya.ml Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sasviya.load_model('artifacts/gb_model.pkl')\n",
    "\n",
    "model_params = {\n",
    "    \"name\": \"GB_Model_ViyaML\",\n",
    "    \"projectId\": project.id,\n",
    "    \"type\": \"ASTORE\"\n",
    "}\n",
    "\n",
    "astore = mr.post(\n",
    "    \"/models\",\n",
    "    files={\"files\": (\"model_export.astore\", model.export())},\n",
    "    data=model_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Sk-Learn Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to Tutorial: https://github.com/sassoftware/python-sasctl/blob/master/examples/pzmm_binary_classification_model_import.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/cleaned_data/train_valid_test.csv')\n",
    "train = df[df['_PartInd_']==1].reset_index(drop=True)\n",
    "test = df[df['_PartInd_']==3].reset_index(drop=True)\n",
    "\n",
    "numerical_features = ['CreditLineAge','DebtIncRatio','FICOScore','Inquiries6Mnths',\n",
    "                      'LogAnnualInc','RevBalance','RevUtilization','Installment','InterestRate']\n",
    "categorical_features = ['CreditPolicy','Delinquencies2Yrs','PublicRecord','Purpose']\n",
    "features = numerical_features+categorical_features\n",
    "target = 'Default'\n",
    "\n",
    "with open('artifacts/data_prep.pkl', mode='rb') as f:\n",
    "    data_prep = pickle.load(f)\n",
    "x_train_prep = pd.DataFrame(data_prep.transform(train[features]), columns=features)\n",
    "x_test_prep = pd.DataFrame(data_prep.transform(test[features]), columns=features)\n",
    "\n",
    "with open('artifacts/sk_model.pkl', mode='rb') as f:\n",
    "    sk_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metrics = [\"I_Default\", \"P_Default1\", \"P_Default0\"]\n",
    "\n",
    "def write_json_files(data, predict, target, path, prefix):    \n",
    "    # Write input variable mapping to a json file\n",
    "    pzmm.JSONFiles.write_var_json(input_data=data[predict], is_input=True, json_path=path)\n",
    "    \n",
    "    # Set output variables and assign an event threshold, then write output variable mapping\n",
    "    output_var = pd.DataFrame(columns=score_metrics, data=[['1', 0.5, 0.5]]) # data argument includes example expected types for outputs\n",
    "    pzmm.JSONFiles.write_var_json(output_var, is_input=False, json_path=path)\n",
    "    \n",
    "    # Write model properties to a json file\n",
    "    pzmm.JSONFiles.write_model_properties_json(\n",
    "        model_name=prefix, \n",
    "        target_variable=target, # Target variable to make predictions about (BAD in this case)\n",
    "        target_values=[\"1\", \"0\"], # Possible values for the target variable (1 or 0 for binary classification of BAD)\n",
    "        json_path=path, \n",
    "        model_desc=f\"Description for the {prefix} model.\",\n",
    "        model_algorithm=\"\",\n",
    "        modeler=\"faceru\",\n",
    "    )\n",
    "    \n",
    "    # Write model metadata to a json file so that SAS Model Manager can properly identify all model files\n",
    "    pzmm.JSONFiles.write_file_metadata_json(model_prefix=prefix, json_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'artifacts/sk_registration'\n",
    "prefix = 'SK_GB'\n",
    "if not os.path.isdir(mypath):\n",
    "   os.makedirs(mypath)\n",
    "\n",
    "pzmm.PickleModel.pickle_trained_model(\n",
    "        model_prefix=prefix,\n",
    "        trained_model=sk_model,\n",
    "        pickle_path=mypath\n",
    "    )\n",
    "write_json_files(x_train_prep, features, target, mypath, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pzmm.ImportModel.import_model(\n",
    "        model_files=mypath, # Where are the model files?\n",
    "        model_prefix=prefix, # What is the model name?\n",
    "        project=project_name, # What is the project name?\n",
    "        input_data=x_train_prep, # What does example input data look like?\n",
    "        predict_method=[sk_model.predict_proba, [int, int]], # What is the predict method and what does it return?\n",
    "        score_metrics=score_metrics, # What are the output variables?\n",
    "        overwrite_model=True, # Overwrite the model if it already exists?\n",
    "        target_values=[\"0\", \"1\"], # What are the expected values of the target variable?\n",
    "        target_index=1, # What is the index of the target value in target_values?\n",
    "        model_file_name=prefix + \".pickle\", # How was the model file serialized?\n",
    "        missing_values=False # Does the data include missing values?\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
